# 作業二：傳統 NLP vs 現代 AI 文本處理方法比較

## 1. 實驗目的與任務說明

本作業針對三項任務，比較傳統方法與現代 AI 方法的差異：

1. 語意相似度計算  
   - 傳統：TF-IDF + Cosine Similarity  
   - 現代：OpenAI `text-embedding-3-small` 向量 + Cosine Similarity  

2. 文本分類  
   - 傳統：規則式情緒分類 + 主題分類（關鍵字計分）  
   - 現代：使用 GPT-4o-mini，輸出 JSON 格式結果（sentiment / topic / confidence）  

3. 自動摘要  
   - 傳統：統計式摘要（句子切分 + 詞頻 / TF-IDF 打分，擷取分數最高的句子）  
   - 現代：GPT-4o-mini 摘要，給定最大字數上限，請模型產生重點整理後的中文摘要  

---

## 2. 實驗設計與資料

### 2.1 語意相似度（Similarity）

共設計 4 組句子 pair，每組人工標記是否「語意相似」（label = 1 或 0），例如：

- 相似例：  
  - 「人工智慧正在改變工作流程，許多重複性工作被自動化。」  
  - 「AI 技術讓企業能自動處理繁瑣的行政工作。」 → label = 1  

- 不相似例：  
  - 「這家餐廳的牛肉麵很好吃，下次還想再來。」  
  - 「這次的會議討論了雲端架構的設計與維運。」 → label = 0  

傳統方法使用 TF-IDF（字元層級）計算 cosine 相似度；  
現代方法使用 OpenAI embedding 計算 cosine 相似度。  
再分別設定門檻（TF-IDF = 0.3，GPT = 0.7）將連續分數轉成二元判斷。

---

### 2.2 文本分類（Classification）

設計 5 句測試文本，每句標記：

- 情緒（sentiment）：正面 / 負面  
- 主題（topic）：科技 / 運動 / 美食 / 旅遊 / 其他  

規則式分類：

- 情緒：依照正向 / 負向關鍵詞加減分，處理「否定 + 情緒詞」時進行分數反轉。  
- 主題：計算各主題關鍵詞在句中出現次數，若全部為 0 則標為「其他」，否則取最高分主題。  

GPT 分類：

- 用 system prompt 限定輸出 JSON：  
  `{"sentiment": "...", "topic": "...", "confidence": 0.xx}`  
- 由 GPT-4o-mini 同時判斷情緒與主題並給出信心分數。

---

### 2.3 自動摘要（Summarization）

選擇 2 篇約數段落的中文文章：

- 一篇為 AI/科技主題  
- 一篇為運動與健康主題  

傳統統計式摘要：

- 以標點符號切句  
- 建立全文詞頻，忽略常見虛詞（停用詞）  
- 對每句計算加總分數並正規化  
- 依比例挑選若干高分句子，維持原順序組成摘要  

GPT 摘要：

- 指定約 120 字的長度上限  
- 要求模型產生精簡摘要、避免逐句翻譯  
- 輸出結果與原文、統計式摘要一併寫入 `summarization_comparison.txt`，方便人工評分  

---

## 3. 定量結果

下列數字來自 `results/performance_metrics.json`。

### 3.1 語意相似度

| 方法             | 門檻 (threshold) | 準確率 | 耗時 (秒)        |
|------------------|------------------|--------|------------------|
| TF-IDF           | 0.3              | 0.50   | 0.0031           |
| GPT Embedding    | 0.7              | 0.50   | 5.3543           |

在目前僅 4 組樣本的設定下，兩者的二元分類準確率同為 0.5。  
但從分數分佈來看，相似 pair 的 GPT 分數（約 0.46–0.57）明顯高於不相似 pair（約 0.21–0.27），  
而 TF-IDF 分數則整體偏低且差異較不明顯。

---

### 3.2 文本分類

| 方法          | 情緒準確率 | 主題準確率 | 耗時 (秒)        |
|---------------|------------|------------|------------------|
| 規則式        | 0.8        | 0.8        | 0.00025          |
| GPT-4o-mini   | 0.8        | 0.8        | 5.8161           |

在本次 5 筆測試資料上，兩者的整體準確率相同，  
但規則式幾乎是瞬間完成；GPT 約需 5.8 秒，時間差距大。

---

### 3.3 自動摘要

| 方法             | 耗時 (秒)       | 備註                        |
|------------------|-----------------|-----------------------------|
| 統計式摘要       | 0.3060          | 依詞頻選句，純本地運算     |
| GPT-4o-mini 摘要 | 6.0010          | API 呼叫，產生流暢摘要    |

資訊保留度與語句通順度則需人工主觀評分，本作業將三種文本摘要對照輸出至 `summarization_comparison.txt`，  
以 0–100% 與 1–5 分量表分別評估資訊保留與語句自然度，觀察結果顯示 GPT 摘要在通順度與結構上明顯優於統計式摘要。

---

## 4. 質性分析

### 4.1 相似度任務

- TF-IDF 對「字面差異大但語意相近」的 pair 分數偏低，很依賴表面詞彙重疊。  
- GPT embedding 能把「人工智慧」與「AI」、「自動化工作流程」與「自動處理行政工作」視為接近概念，  
  相似 pair 分數整體高於不相似 pair。  
- 在少量樣本下準確率相同，顯示未來若要放大樣本數，GPT 在語意層次上的優勢較有機會被顯現。

### 4.2 文本分類任務

- 規則式方法的行為高度可預期，對關鍵字明顯出現的句子判斷良好；  
  但當句子措辭較委婉（例如「有點累但覺得值得」）或帶有否定語氣時，就需要不斷人工調整規則。  
- GPT-4o-mini 在本次小型資料上與規則式有相同準確率，  
  實際觀察輸出可以看出它有能力從整體語氣與上下文來推斷主題與情緒，  
  對「同時出現多個領域關鍵詞」的句子處理較穩定。

### 4.3 摘要任務

- 統計式摘要偏向「擷取原文片段」，適合用來快速抓出關鍵句，  
  但句與句之間缺乏重新組織與銜接，讀起來較像「剪貼集合」。  
- GPT 摘要則會主動重寫句子，使語氣與段落更連貫，同時保留關鍵因果與主題，  
  閱讀體驗明顯較好，但需要付出額外的時間與 API 成本。

---

## 5. 總結與反思

本作業中，傳統 NLP 方法展現出輕量、快速、可解釋的優勢，  
尤其在小規模、對成本敏感的場景中仍然非常實用；  
現代 AI 方法則提供更強的語意理解與更自然的生成能力，  
適合應用在需要高品質輸出的任務，例如摘要、進階分類與語意檢索。

實作過程中也可以感受到，如果只使用黑盒模型，  
一旦結果不如預期，比較難追蹤問題來源；  
相反地，先實作一次 TF-IDF、規則式與統計式摘要，  
可以幫助自己在調整 GPT prompt 或解讀結果時更有「底層感」，  
這也是傳統方法在現代 AI 時代仍值得學習與保留的理由之一。
